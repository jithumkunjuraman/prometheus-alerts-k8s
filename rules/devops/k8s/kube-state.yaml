- name: kube-state-alerts
  rules:
   - alert: KubernetesNodeReady
     expr: kube_node_status_condition{condition="Ready",status="true"} == 0
     for: 30m
     labels:
       severity: critical
       group: devops
     annotations:
       summary: "Kubernetes Node ready (instance {{ $labels.instance }})"
       description: "Node {{ $labels.node }} has been unready for a long time\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

   - alert: KubernetesMemoryPressure
     expr: kube_node_status_condition{condition="MemoryPressure",status="true"} == 1
     for: 5m
     labels:
       severity: critical
       group: devops
     annotations:
       summary: "Kubernetes memory pressure (instance {{ $labels.instance }})"
       description: "{{ $labels.node }} has MemoryPressure condition\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}" 

   - alert: KubernetesDiskPressure
     expr: kube_node_status_condition{condition="DiskPressure",status="true"} == 1
     for: 15m
     labels:
       severity: critical
       group: devops
     annotations:
       summary: "Kubernetes disk pressure (instance {{ $labels.instance }})"
       description: "{{ $labels.node }} has DiskPressure condition\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}" 

   - alert: KubernetesOutOfDisk
     expr: kube_node_status_condition{condition="OutOfDisk",status="true"} == 1
     for: 5m
     labels:
       severity: critical
       group: devops
     annotations:
       summary: "Kubernetes out of disk (instance {{ $labels.instance }})"
       description: "{{ $labels.node }} has OutOfDisk condition\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"  
       
   - alert: KubernetesJobFailed
     expr: kube_job_status_failed{namespace!="observability",namespace!="user-insights"} > 0
     for: 5m
     labels:
       severity: warning
       group: devops
     annotations:
       summary: "Kubernetes Job failed (instance {{ $labels.instance }})"
       description: "Job {{$labels.namespace}}/{{$labels.exported_job}} failed to complete\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"            

   - alert: KubernetesCronjobSuspended
     expr: kube_cronjob_spec_suspend != 0
     for: 5m
     labels:
       severity: warning
       group: devops
     annotations:
       summary: "Kubernetes CronJob suspended (instance {{ $labels.instance }})"
       description: "CronJob {{ $labels.namespace }}/{{ $labels.cronjob }} is suspended\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
             
   - alert: KubernetesPersistentvolumeclaimPending
     expr: kube_persistentvolumeclaim_status_phase{phase="Pending"} == 1
     for: 15m
     labels:
       severity: warning
       group: devops
     annotations:
       summary: "Kubernetes PersistentVolumeClaim pending (instance {{ $labels.instance }})"
       description: "PersistentVolumeClaim {{ $labels.namespace }}/{{ $labels.persistentvolumeclaim }} is pending\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"          

   - alert: KubernetesVolumeOutOfDiskSpace
     expr: kubelet_volume_stats_available_bytes / kubelet_volume_stats_capacity_bytes * 100 < 10
     for: 5m
     labels:
       severity: warning
       group: devops
     annotations:
       summary: "Kubernetes Volume out of disk space (instance {{ $labels.instance }})"
       description: "Volume is almost full (< 10% left)\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"    
       
   - alert: KubernetesPersistentvolumeError
     expr: kube_persistentvolume_status_phase{phase=~"Failed|Pending",job="kube-state-metrics"} > 0
     for: 5m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes PersistentVolume error (instance {{ $labels.instance }})"
       description: "Persistent volume is in bad state\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"

   - alert: KubernetesStatefulsetDown
     expr: (kube_statefulset_status_replicas_ready{namespace!="observability"} / kube_statefulset_status_replicas_current{namespace!="observability"}) != 1
     for: 5m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes StatefulSet down (instance {{ $labels.instance }})"
       description: "A StatefulSet went down\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"   
 
   - alert: KubernetesHpaMetricAvailability
     expr: kube_hpa_status_condition{condition="false", status="ScalingActive"} == 1
     for: 5m
     labels:
       severity: warning
     annotations:
       summary: "Kubernetes HPA metric availability (instance {{ $labels.instance }})"
       description: "HPA is not able to colelct metrics\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"  

   - alert: KubernetesHpaScaleCapability
     expr: kube_hpa_status_desired_replicas{namespace!="observability"} >= kube_hpa_spec_max_replicas{namespace!="observability"}
     for: 5m
     labels:
       severity: warning
     annotations:
       summary: "Kubernetes HPA scale capability (instance {{ $labels.instance }})"
       description: "The maximum number of desired Pods has been hit\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"            

   - alert: KubernetesPodCrashLooping
     expr: rate(kube_pod_container_status_restarts_total[15m]) * 60 * 5 > 5
     for: 10m
     labels:
       severity: warning
     annotations:
       summary: "Kubernetes pod crash looping (instance {{ $labels.instance }})"
       description: "Pod {{ $labels.pod }} is crash looping\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"   
       
   - alert: KubernetesStatefulsetReplicasMismatch
     expr: kube_statefulset_status_replicas_ready != kube_statefulset_status_replicas
     for: 5m
     labels:
       severity: warning
     annotations:
       summary: "Kubernetes StatefulSet replicas mismatch (instance {{ $labels.instance }})"
       description: "A StatefulSet has not matched the expected number of replicas for longer than 15 minutes.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"            

   - alert: KubernetesDeploymentGenerationMismatch
     expr: kube_deployment_status_observed_generation != kube_deployment_metadata_generation
     for: 15m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes Deployment generation mismatch (instance {{ $labels.instance }})"
       description: "A Deployment has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"            

   - alert: KubernetesStatefulsetGenerationMismatch
     expr: kube_statefulset_status_observed_generation != kube_statefulset_metadata_generation
     for: 15m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes StatefulSet generation mismatch (instance {{ $labels.instance }})"
       description: "A StatefulSet has failed but has not been rolled back.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"            

   - alert: KubernetesStatefulsetUpdateNotRolledOut
     expr: max without (revision) (kube_statefulset_status_current_revision unless kube_statefulset_status_update_revision) * (kube_statefulset_replicas != kube_statefulset_status_replicas_updated)
     for: 30m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes StatefulSet update not rolled out (instance {{ $labels.instance }})"
       description: "StatefulSet update has not been rolled out.\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"   
       
   - alert: KubernetesDaemonsetRolloutStuck
     expr: kube_daemonset_status_number_ready{daemonset!="metricbeat"} / kube_daemonset_status_desired_number_scheduled * 100 < 100 or kube_daemonset_status_desired_number_scheduled - kube_daemonset_status_current_number_scheduled > 0
     for: 30m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes DaemonSet rollout stuck (instance {{ $labels.instance }})"
       description: "Some Pods of DaemonSet are not scheduled or not ready\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"            
     
   - alert: KubernetesDaemonsetMisscheduled
     expr: kube_daemonset_status_number_misscheduled > 0
     for: 30m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes DaemonSet misscheduled (instance {{ $labels.instance }})"
       description: "Some DaemonSet Pods are running where they are not supposed to run\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"  
       
   - alert: KubernetesJobCompletion
     expr: kube_job_spec_completions{namespace!="observability",namespace!="observability"} - kube_job_status_succeeded{namespace!="observability",namespace!="user-insights"} > 0 or kube_job_status_failed{namespace!="observability"} > 0
     for: 15m
     labels:
       severity: error
     annotations:
       summary: "Kubernetes job completion (instance {{ $labels.instance }})"
       description: "Kubernetes Job failed to complete\n  VALUE = {{ $value }}\n  LABELS: {{ $labels }}"
